=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu DeviceId=0 timestamping=true numCPUThreads=1 stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 2 in a gearbox of 4
mpihelper: we are cog 0 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 1 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
mpihelper: we are cog 3 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: 04/22/2016 01:00:46: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank0
MPI Rank 0: 04/22/2016 01:00:46: -------------------------------------------------------------------
MPI Rank 0: 04/22/2016 01:00:46: Build info: 
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: 		Built time: Apr 21 2016 15:42:22
MPI Rank 0: 04/22/2016 01:00:46: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 0: 04/22/2016 01:00:46: 		Build type: Release
MPI Rank 0: 04/22/2016 01:00:46: 		Build target: GPU
MPI Rank 0: 04/22/2016 01:00:46: 		With 1bit-SGD: no
MPI Rank 0: 04/22/2016 01:00:46: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 0: 04/22/2016 01:00:46: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 0: 04/22/2016 01:00:46: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 04/22/2016 01:00:46: 		Build Branch: HEAD
MPI Rank 0: 04/22/2016 01:00:46: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 0: 04/22/2016 01:00:46: 		Built by svcphil on liana-08-w
MPI Rank 0: 04/22/2016 01:00:46: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 0: 04/22/2016 01:00:46: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: Running on cntk-muc00 at 2016/04/22 01:00:46
MPI Rank 0: 04/22/2016 01:00:46: Command line: 
MPI Rank 0: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/22/2016 01:00:46: modelPath=$RunDir$/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/22/2016 01:00:46: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 0: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:timestamping=true
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 04/22/2016 01:00:46: Commands: train
MPI Rank 0: 04/22/2016 01:00:46: Precision = "float"
MPI Rank 0: 04/22/2016 01:00:46: Using 1 CPU threads.
MPI Rank 0: 04/22/2016 01:00:46: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0: 04/22/2016 01:00:46: CNTKCommandTrainInfo: train : 3
MPI Rank 0: 04/22/2016 01:00:46: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: ##############################################################################
MPI Rank 0: 04/22/2016 01:00:46: #                                                                            #
MPI Rank 0: 04/22/2016 01:00:46: # Action "train"                                                             #
MPI Rank 0: 04/22/2016 01:00:46: #                                                                            #
MPI Rank 0: 04/22/2016 01:00:46: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: Creating virgin network.
MPI Rank 0: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	CE = CrossEntropyWithSoftmax()
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 0: 
MPI Rank 0: Validating network. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 0: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 0: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 0: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 0: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 0: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 0: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 0: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 0: 
MPI Rank 0: Validating network. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: Created model with 21 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:46: Training criterion node(s):
MPI Rank 0: 04/22/2016 01:00:46: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 04/22/2016 01:00:46: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:49: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:00:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/22/2016 01:00:56:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.34696846; TotalTime = 7.0496s; SamplesPerSecond = 1452.6
MPI Rank 0: 04/22/2016 01:01:03:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.34277382; TotalTime = 6.6471s; SamplesPerSecond = 1540.5
MPI Rank 0: 04/22/2016 01:01:07: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3731
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001547    Perplexity = 12.184379    
MPI Rank 0: 04/22/2016 01:01:10: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001547
MPI Rank 0: 04/22/2016 01:01:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net.1'
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:01:13: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:01:13: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/22/2016 01:01:20:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.30270958; TotalTime = 6.9493s; SamplesPerSecond = 1473.5
MPI Rank 0: 04/22/2016 01:01:27:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.09883766; TotalTime = 6.7394s; SamplesPerSecond = 1519.4
MPI Rank 0: 04/22/2016 01:01:30: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757752; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3307
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810995    
MPI Rank 0: 04/22/2016 01:01:33: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 0: 04/22/2016 01:01:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net.2'
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:01:36: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:01:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/22/2016 01:01:44:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.89778175; TotalTime = 7.1714s; SamplesPerSecond = 1427.9
MPI Rank 0: 04/22/2016 01:01:51:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86335983; TotalTime = 6.8506s; SamplesPerSecond = 1494.8
MPI Rank 0: 04/22/2016 01:01:54: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.4499
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050029    
MPI Rank 0: 04/22/2016 01:01:56: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 0: 04/22/2016 01:01:58: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net'
MPI Rank 0: 04/22/2016 01:01:59: CNTKCommandTrainEnd: train
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:01:59: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:01:59: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 04/22/2016 01:00:46: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank1
MPI Rank 1: 04/22/2016 01:00:46: -------------------------------------------------------------------
MPI Rank 1: 04/22/2016 01:00:46: Build info: 
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: 		Built time: Apr 21 2016 15:42:22
MPI Rank 1: 04/22/2016 01:00:46: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 1: 04/22/2016 01:00:46: 		Build type: Release
MPI Rank 1: 04/22/2016 01:00:46: 		Build target: GPU
MPI Rank 1: 04/22/2016 01:00:46: 		With 1bit-SGD: no
MPI Rank 1: 04/22/2016 01:00:46: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 1: 04/22/2016 01:00:46: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 1: 04/22/2016 01:00:46: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 04/22/2016 01:00:46: 		Build Branch: HEAD
MPI Rank 1: 04/22/2016 01:00:46: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 1: 04/22/2016 01:00:46: 		Built by svcphil on liana-08-w
MPI Rank 1: 04/22/2016 01:00:46: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 1: 04/22/2016 01:00:46: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: Running on cntk-muc00 at 2016/04/22 01:00:46
MPI Rank 1: 04/22/2016 01:00:46: Command line: 
MPI Rank 1: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/22/2016 01:00:46: modelPath=$RunDir$/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/22/2016 01:00:46: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 1: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:timestamping=true
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 04/22/2016 01:00:46: Commands: train
MPI Rank 1: 04/22/2016 01:00:46: Precision = "float"
MPI Rank 1: 04/22/2016 01:00:46: Using 1 CPU threads.
MPI Rank 1: 04/22/2016 01:00:46: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1: 04/22/2016 01:00:46: CNTKCommandTrainInfo: train : 3
MPI Rank 1: 04/22/2016 01:00:46: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: ##############################################################################
MPI Rank 1: 04/22/2016 01:00:46: #                                                                            #
MPI Rank 1: 04/22/2016 01:00:46: # Action "train"                                                             #
MPI Rank 1: 04/22/2016 01:00:46: #                                                                            #
MPI Rank 1: 04/22/2016 01:00:46: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:46: Creating virgin network.
MPI Rank 1: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	CE = CrossEntropyWithSoftmax()
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 1: 
MPI Rank 1: Validating network. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 1: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 1: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 1: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 1: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 1: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 1: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 1: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 1: 
MPI Rank 1: Validating network. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:47: Created model with 21 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:47: Training criterion node(s):
MPI Rank 1: 04/22/2016 01:00:47: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 04/22/2016 01:00:47: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:49: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:00:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/22/2016 01:00:56:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32159615; TotalTime = 7.0632s; SamplesPerSecond = 1449.8
MPI Rank 1: 04/22/2016 01:01:03:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.33525505; TotalTime = 6.6544s; SamplesPerSecond = 1538.8
MPI Rank 1: 04/22/2016 01:01:07: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3728
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001547    Perplexity = 12.184379    
MPI Rank 1: 04/22/2016 01:01:10: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001547
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:01:13: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:01:13: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/22/2016 01:01:20:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32732925; TotalTime = 6.9537s; SamplesPerSecond = 1472.6
MPI Rank 1: 04/22/2016 01:01:27:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11035957; TotalTime = 6.6987s; SamplesPerSecond = 1528.7
MPI Rank 1: 04/22/2016 01:01:30: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757752; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3289
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810995    
MPI Rank 1: 04/22/2016 01:01:33: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:01:36: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:01:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/22/2016 01:01:44:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.92909813; TotalTime = 7.2371s; SamplesPerSecond = 1414.9
MPI Rank 1: 04/22/2016 01:01:51:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.86598778; TotalTime = 6.8674s; SamplesPerSecond = 1491.1
MPI Rank 1: 04/22/2016 01:01:54: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.4463
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050029    
MPI Rank 1: 04/22/2016 01:01:56: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 1: 04/22/2016 01:01:59: CNTKCommandTrainEnd: train
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:01:59: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:01:59: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: 04/22/2016 01:00:47: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank2
MPI Rank 2: 04/22/2016 01:00:47: -------------------------------------------------------------------
MPI Rank 2: 04/22/2016 01:00:47: Build info: 
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: 		Built time: Apr 21 2016 15:42:22
MPI Rank 2: 04/22/2016 01:00:47: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 2: 04/22/2016 01:00:47: 		Build type: Release
MPI Rank 2: 04/22/2016 01:00:47: 		Build target: GPU
MPI Rank 2: 04/22/2016 01:00:47: 		With 1bit-SGD: no
MPI Rank 2: 04/22/2016 01:00:47: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 2: 04/22/2016 01:00:47: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 2: 04/22/2016 01:00:47: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 04/22/2016 01:00:47: 		Build Branch: HEAD
MPI Rank 2: 04/22/2016 01:00:47: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 2: 04/22/2016 01:00:47: 		Built by svcphil on liana-08-w
MPI Rank 2: 04/22/2016 01:00:47: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 2: 04/22/2016 01:00:47: -------------------------------------------------------------------
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: Running on cntk-muc00 at 2016/04/22 01:00:47
MPI Rank 2: 04/22/2016 01:00:47: Command line: 
MPI Rank 2: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/22/2016 01:00:47: modelPath=$RunDir$/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=1
MPI Rank 2: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/22/2016 01:00:47: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=1
MPI Rank 2: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 2: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:timestamping=true
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 04/22/2016 01:00:47: Commands: train
MPI Rank 2: 04/22/2016 01:00:47: Precision = "float"
MPI Rank 2: 04/22/2016 01:00:47: Using 1 CPU threads.
MPI Rank 2: 04/22/2016 01:00:47: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2: 04/22/2016 01:00:47: CNTKCommandTrainInfo: train : 3
MPI Rank 2: 04/22/2016 01:00:47: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: ##############################################################################
MPI Rank 2: 04/22/2016 01:00:47: #                                                                            #
MPI Rank 2: 04/22/2016 01:00:47: # Action "train"                                                             #
MPI Rank 2: 04/22/2016 01:00:47: #                                                                            #
MPI Rank 2: 04/22/2016 01:00:47: ##############################################################################
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: Creating virgin network.
MPI Rank 2: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	CE = CrossEntropyWithSoftmax()
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 2: 
MPI Rank 2: Validating network. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 2: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 2: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 2: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 2: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 2: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 2: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 2: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 2: 
MPI Rank 2: Validating network. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network, final pass.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: Created model with 21 nodes on GPU 0.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:47: Training criterion node(s):
MPI Rank 2: 04/22/2016 01:00:47: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 04/22/2016 01:00:47: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:49: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:00:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/22/2016 01:00:56:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32837524; TotalTime = 7.0664s; SamplesPerSecond = 1449.1
MPI Rank 2: 04/22/2016 01:01:03:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35655518; TotalTime = 6.6126s; SamplesPerSecond = 1548.6
MPI Rank 2: 04/22/2016 01:01:07: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3731
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001547    Perplexity = 12.184379    
MPI Rank 2: 04/22/2016 01:01:10: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001547
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:01:13: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:01:13: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/22/2016 01:01:20:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.32893581; TotalTime = 6.9507s; SamplesPerSecond = 1473.2
MPI Rank 2: 04/22/2016 01:01:27:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11646900; TotalTime = 6.7615s; SamplesPerSecond = 1514.5
MPI Rank 2: 04/22/2016 01:01:30: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757752; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3307
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810995    
MPI Rank 2: 04/22/2016 01:01:33: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:01:36: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:01:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/22/2016 01:01:44:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.95308418; TotalTime = 7.2604s; SamplesPerSecond = 1410.4
MPI Rank 2: 04/22/2016 01:01:51:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.87902641; TotalTime = 6.8159s; SamplesPerSecond = 1502.4
MPI Rank 2: 04/22/2016 01:01:54: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.4709
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050029    
MPI Rank 2: 04/22/2016 01:01:56: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 2: 04/22/2016 01:01:59: CNTKCommandTrainEnd: train
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:01:59: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:01:59: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: 04/22/2016 01:00:47: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 3: 04/22/2016 01:00:47: -------------------------------------------------------------------
MPI Rank 3: 04/22/2016 01:00:47: Build info: 
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: 		Built time: Apr 21 2016 15:42:22
MPI Rank 3: 04/22/2016 01:00:47: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 3: 04/22/2016 01:00:47: 		Build type: Release
MPI Rank 3: 04/22/2016 01:00:47: 		Build target: GPU
MPI Rank 3: 04/22/2016 01:00:47: 		With 1bit-SGD: no
MPI Rank 3: 04/22/2016 01:00:47: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 3: 04/22/2016 01:00:47: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 3: 04/22/2016 01:00:47: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 04/22/2016 01:00:47: 		Build Branch: HEAD
MPI Rank 3: 04/22/2016 01:00:47: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 3: 04/22/2016 01:00:47: 		Built by svcphil on liana-08-w
MPI Rank 3: 04/22/2016 01:00:47: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 3: 04/22/2016 01:00:47: -------------------------------------------------------------------
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: Running on cntk-muc00 at 2016/04/22 01:00:47
MPI Rank 3: 04/22/2016 01:00:47: Command line: 
MPI Rank 3: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/22/2016 01:00:47: modelPath=$RunDir$/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:         keepCheckPointFiles = true
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=1
MPI Rank 3: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/22/2016 01:00:47: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:         keepCheckPointFiles = true
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=1
MPI Rank 3: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 3: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:timestamping=true
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:         keepCheckPointFiles = true
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 04/22/2016 01:00:47: Commands: train
MPI Rank 3: 04/22/2016 01:00:47: Precision = "float"
MPI Rank 3: 04/22/2016 01:00:47: Using 1 CPU threads.
MPI Rank 3: 04/22/2016 01:00:47: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3: 04/22/2016 01:00:47: CNTKCommandTrainInfo: train : 3
MPI Rank 3: 04/22/2016 01:00:47: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: ##############################################################################
MPI Rank 3: 04/22/2016 01:00:47: #                                                                            #
MPI Rank 3: 04/22/2016 01:00:47: # Action "train"                                                             #
MPI Rank 3: 04/22/2016 01:00:47: #                                                                            #
MPI Rank 3: 04/22/2016 01:00:47: ##############################################################################
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:47: Creating virgin network.
MPI Rank 3: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	CE = CrossEntropyWithSoftmax()
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 3: 
MPI Rank 3: Validating network. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *]
MPI Rank 3: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Query = SparseInputValue() :  -> [49292 x *]
MPI Rank 3: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *] -> [288 x *]
MPI Rank 3: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *] -> [64 x *]
MPI Rank 3: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue() :  -> [49292 x *]
MPI Rank 3: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *] -> [288 x *]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *] -> [288 x *]
MPI Rank 3: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *] -> [64 x *]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *] -> [64 x *]
MPI Rank 3: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *], [64 x *], [1 x 1], [1 x 1] -> [51 x *]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *] -> [51 x 1 x *]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *], [51 x 1 x *] -> [1]
MPI Rank 3: 
MPI Rank 3: Validating network. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating network, final pass.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:48: Created model with 21 nodes on GPU 0.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:48: Training criterion node(s):
MPI Rank 3: 04/22/2016 01:00:48: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: 04/22/2016 01:00:48: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:49: Starting Epoch 1: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:00:49: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/22/2016 01:00:56:  Epoch[ 1 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  4.32287750; TotalTime = 7.0794s; SamplesPerSecond = 1446.4
MPI Rank 3: 04/22/2016 01:01:03:  Epoch[ 1 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  3.35470428; TotalTime = 6.6543s; SamplesPerSecond = 1538.9
MPI Rank 3: 04/22/2016 01:01:07: Finished Epoch[ 1 of 3]: [Training Set] TrainLossPerSample = 3.6160171; TotalSamplesSeen = 102399; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3727
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 2.5001547    Perplexity = 12.184379    
MPI Rank 3: 04/22/2016 01:01:10: Finished Epoch[ 1 of 3]: [Validation Set] TrainLossPerSample = 2.5001547
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:01:13: Starting Epoch 2: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:01:13: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/22/2016 01:01:20:  Epoch[ 2 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.29653873; TotalTime = 6.9798s; SamplesPerSecond = 1467.1
MPI Rank 3: 04/22/2016 01:01:27:  Epoch[ 2 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  2.11679478; TotalTime = 6.7220s; SamplesPerSecond = 1523.3
MPI Rank 3: 04/22/2016 01:01:30: Finished Epoch[ 2 of 3]: [Training Set] TrainLossPerSample = 2.1757752; TotalSamplesSeen = 204798; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.3271
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.9714525    Perplexity = 7.1810995    
MPI Rank 3: 04/22/2016 01:01:33: Finished Epoch[ 2 of 3]: [Validation Set] TrainLossPerSample = 1.9714525
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:01:36: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:01:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/22/2016 01:01:44:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.90347195; TotalTime = 7.2529s; SamplesPerSecond = 1411.9
MPI Rank 3: 04/22/2016 01:01:51:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.88304119; TotalTime = 6.8602s; SamplesPerSecond = 1492.7
MPI Rank 3: 04/22/2016 01:01:54: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8856394; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=17.4463
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.8091086    Perplexity = 6.1050029    
MPI Rank 3: 04/22/2016 01:01:56: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.8091086
MPI Rank 3: 04/22/2016 01:01:59: CNTKCommandTrainEnd: train
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:01:59: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:01:59: __COMPLETED__
MPI Rank 3: ~MPIWrapper
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 4 C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu DeviceId=0 timestamping=true numCPUThreads=1 stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Apr 21 2016 15:42:22
		Last modified date: Sun Apr 17 20:45:43 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
		Built by svcphil on liana-08-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (1) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (3) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (before change)]: all 4 nodes responded
ping [requestnodes (before change)]: all 4 nodes responded
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 4 out of 4 MPI nodes (4 requested); we (2) are in (participating)
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 2 in a gearbox of 4
mpihelper: we are cog 0 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [requestnodes (after change)]: all 4 nodes responded
ping [requestnodes (after change)]: all 4 nodes responded
mpihelper: we are cog 1 in a gearbox of 4
mpihelper: we are cog 3 in a gearbox of 4
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: 4 nodes pinging each other
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
ping [mpihelper]: all 4 nodes responded
MPI Rank 0: 04/22/2016 01:02:02: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank0
MPI Rank 0: 04/22/2016 01:02:02: -------------------------------------------------------------------
MPI Rank 0: 04/22/2016 01:02:02: Build info: 
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: 		Built time: Apr 21 2016 15:42:22
MPI Rank 0: 04/22/2016 01:02:02: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 0: 04/22/2016 01:02:02: 		Build type: Release
MPI Rank 0: 04/22/2016 01:02:02: 		Build target: GPU
MPI Rank 0: 04/22/2016 01:02:02: 		With 1bit-SGD: no
MPI Rank 0: 04/22/2016 01:02:02: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 0: 04/22/2016 01:02:02: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 0: 04/22/2016 01:02:02: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 04/22/2016 01:02:02: 		Build Branch: HEAD
MPI Rank 0: 04/22/2016 01:02:02: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 0: 04/22/2016 01:02:02: 		Built by svcphil on liana-08-w
MPI Rank 0: 04/22/2016 01:02:02: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 0: 04/22/2016 01:02:02: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: Running on cntk-muc00 at 2016/04/22 01:02:02
MPI Rank 0: 04/22/2016 01:02:02: Command line: 
MPI Rank 0: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/22/2016 01:02:02: modelPath=$RunDir$/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=$DeviceId$
MPI Rank 0:     minibatchSize = $MBSize$
MPI Rank 0:     modelPath = $modelPath$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = $LRate$
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = $DataDir$/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 04/22/2016 01:02:02: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0: MBSize=4096
MPI Rank 0: LRate=0.0001
MPI Rank 0: DeviceId=-1
MPI Rank 0: parallelTrain=true
MPI Rank 0: command = train
MPI Rank 0: precision = float
MPI Rank 0: traceGPUMemoryAllocations=0
MPI Rank 0: train = [
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: NDLNetworkBuilder = [
MPI Rank 0:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: reader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: cvReader = [
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: dssm.cntk:command=train
MPI Rank 0: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 0: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:cvReader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 0: configparameters: dssm.cntk:DeviceId=0
MPI Rank 0: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 0: configparameters: dssm.cntk:MBSize=4096
MPI Rank 0: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 0:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 0: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 0: configparameters: dssm.cntk:precision=float
MPI Rank 0: configparameters: dssm.cntk:reader=[
MPI Rank 0:     readerType = LibSVMBinaryReader
MPI Rank 0:     miniBatchMode = Partial
MPI Rank 0:     randomize = 0
MPI Rank 0:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 0: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 0: configparameters: dssm.cntk:timestamping=true
MPI Rank 0: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 0: configparameters: dssm.cntk:train=[
MPI Rank 0:     action = train
MPI Rank 0:     numMBsToShowResult=10
MPI Rank 0:     deviceId=0
MPI Rank 0:     minibatchSize = 4096
MPI Rank 0:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize=102399
MPI Rank 0:         learningRatesPerSample = 0.0001
MPI Rank 0:         momentumPerMB = 0.9
MPI Rank 0:         maxEpochs=3
MPI Rank 0:         ParallelTrain=[
MPI Rank 0:             parallelizationStartEpoch=1
MPI Rank 0:             parallelizationMethod=ModelAveragingSGD
MPI Rank 0:             distributedMBReading=true
MPI Rank 0:             ModelAveragingSGD=[
MPI Rank 0:                 SyncFrequencyInFrames=1024
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0: 		gradUpdateType=none
MPI Rank 0: 		gradientClippingWithTruncation=true
MPI Rank 0: 		clippingThresholdPerSample=1#INF
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 04/22/2016 01:02:02: Commands: train
MPI Rank 0: 04/22/2016 01:02:02: Precision = "float"
MPI Rank 0: 04/22/2016 01:02:02: Using 1 CPU threads.
MPI Rank 0: 04/22/2016 01:02:02: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 0: 04/22/2016 01:02:02: CNTKCommandTrainInfo: train : 3
MPI Rank 0: 04/22/2016 01:02:02: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: ##############################################################################
MPI Rank 0: 04/22/2016 01:02:02: #                                                                            #
MPI Rank 0: 04/22/2016 01:02:02: # Action "train"                                                             #
MPI Rank 0: 04/22/2016 01:02:02: #                                                                            #
MPI Rank 0: 04/22/2016 01:02:02: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: CNTKCommandTrainBegin: train
MPI Rank 0: NDLBuilder Using GPU 0
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:02: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 2 roots:
MPI Rank 0: 	CE = CrossEntropyWithSoftmax()
MPI Rank 0: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 0: 
MPI Rank 0: Validating network. 21 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *1]
MPI Rank 0: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Query = SparseInputValue() :  -> [49292 x *1]
MPI Rank 0: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 0: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *1] -> [288 x *1]
MPI Rank 0: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 0: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *1] -> [64 x *1]
MPI Rank 0: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 0: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 0: Validating --> Keyword = SparseInputValue() :  -> [49292 x *1]
MPI Rank 0: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 0: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *1] -> [288 x *1]
MPI Rank 0: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 0: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *1] -> [64 x *1]
MPI Rank 0: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 0: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *1], [64 x *1], [1 x 1], [1 x 1] -> [51 x *1]
MPI Rank 0: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *1] -> [51 x 1 x *1]
MPI Rank 0: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *1], [51 x 1 x *1] -> [1]
MPI Rank 0: 
MPI Rank 0: Validating network. 11 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:05: Loaded model with 21 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:05: Training criterion node(s):
MPI Rank 0: 04/22/2016 01:02:05: 	CE = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 04/22/2016 01:02:05: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:08: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 04/22/2016 01:02:15:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.87577038; TotalTime = 6.8377s; SamplesPerSecond = 1497.6
MPI Rank 0: 04/22/2016 01:02:21:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.79361134; TotalTime = 6.6210s; SamplesPerSecond = 1546.6
MPI Rank 0: 04/22/2016 01:02:24: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8897429; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=16.7174
MPI Rank 0: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.820068    Perplexity = 6.1722783    
MPI Rank 0: 04/22/2016 01:02:27: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.820068
MPI Rank 0: 04/22/2016 01:02:29: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net'
MPI Rank 0: 04/22/2016 01:02:30: CNTKCommandTrainEnd: train
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:30: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 04/22/2016 01:02:30: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 04/22/2016 01:02:03: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank1
MPI Rank 1: 04/22/2016 01:02:03: -------------------------------------------------------------------
MPI Rank 1: 04/22/2016 01:02:03: Build info: 
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: 		Built time: Apr 21 2016 15:42:22
MPI Rank 1: 04/22/2016 01:02:03: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 1: 04/22/2016 01:02:03: 		Build type: Release
MPI Rank 1: 04/22/2016 01:02:03: 		Build target: GPU
MPI Rank 1: 04/22/2016 01:02:03: 		With 1bit-SGD: no
MPI Rank 1: 04/22/2016 01:02:03: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 1: 04/22/2016 01:02:03: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 1: 04/22/2016 01:02:03: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 04/22/2016 01:02:03: 		Build Branch: HEAD
MPI Rank 1: 04/22/2016 01:02:03: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 1: 04/22/2016 01:02:03: 		Built by svcphil on liana-08-w
MPI Rank 1: 04/22/2016 01:02:03: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 1: 04/22/2016 01:02:03: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: Running on cntk-muc00 at 2016/04/22 01:02:03
MPI Rank 1: 04/22/2016 01:02:03: Command line: 
MPI Rank 1: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/22/2016 01:02:03: modelPath=$RunDir$/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=$DeviceId$
MPI Rank 1:     minibatchSize = $MBSize$
MPI Rank 1:     modelPath = $modelPath$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = $LRate$
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = $DataDir$/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 04/22/2016 01:02:03: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1: MBSize=4096
MPI Rank 1: LRate=0.0001
MPI Rank 1: DeviceId=-1
MPI Rank 1: parallelTrain=true
MPI Rank 1: command = train
MPI Rank 1: precision = float
MPI Rank 1: traceGPUMemoryAllocations=0
MPI Rank 1: train = [
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: NDLNetworkBuilder = [
MPI Rank 1:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: reader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: cvReader = [
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: dssm.cntk:command=train
MPI Rank 1: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 1: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:cvReader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 1: configparameters: dssm.cntk:DeviceId=0
MPI Rank 1: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 1: configparameters: dssm.cntk:MBSize=4096
MPI Rank 1: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 1:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 1: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 1: configparameters: dssm.cntk:precision=float
MPI Rank 1: configparameters: dssm.cntk:reader=[
MPI Rank 1:     readerType = LibSVMBinaryReader
MPI Rank 1:     miniBatchMode = Partial
MPI Rank 1:     randomize = 0
MPI Rank 1:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 1: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 1: configparameters: dssm.cntk:timestamping=true
MPI Rank 1: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 1: configparameters: dssm.cntk:train=[
MPI Rank 1:     action = train
MPI Rank 1:     numMBsToShowResult=10
MPI Rank 1:     deviceId=0
MPI Rank 1:     minibatchSize = 4096
MPI Rank 1:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize=102399
MPI Rank 1:         learningRatesPerSample = 0.0001
MPI Rank 1:         momentumPerMB = 0.9
MPI Rank 1:         maxEpochs=3
MPI Rank 1:         ParallelTrain=[
MPI Rank 1:             parallelizationStartEpoch=1
MPI Rank 1:             parallelizationMethod=ModelAveragingSGD
MPI Rank 1:             distributedMBReading=true
MPI Rank 1:             ModelAveragingSGD=[
MPI Rank 1:                 SyncFrequencyInFrames=1024
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1: 		gradUpdateType=none
MPI Rank 1: 		gradientClippingWithTruncation=true
MPI Rank 1: 		clippingThresholdPerSample=1#INF
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 04/22/2016 01:02:03: Commands: train
MPI Rank 1: 04/22/2016 01:02:03: Precision = "float"
MPI Rank 1: 04/22/2016 01:02:03: Using 1 CPU threads.
MPI Rank 1: 04/22/2016 01:02:03: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 1: 04/22/2016 01:02:03: CNTKCommandTrainInfo: train : 3
MPI Rank 1: 04/22/2016 01:02:03: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: ##############################################################################
MPI Rank 1: 04/22/2016 01:02:03: #                                                                            #
MPI Rank 1: 04/22/2016 01:02:03: # Action "train"                                                             #
MPI Rank 1: 04/22/2016 01:02:03: #                                                                            #
MPI Rank 1: 04/22/2016 01:02:03: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: CNTKCommandTrainBegin: train
MPI Rank 1: NDLBuilder Using GPU 0
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:03: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 2 roots:
MPI Rank 1: 	CE = CrossEntropyWithSoftmax()
MPI Rank 1: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 1: 
MPI Rank 1: Validating network. 21 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *1]
MPI Rank 1: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Query = SparseInputValue() :  -> [49292 x *1]
MPI Rank 1: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 1: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *1] -> [288 x *1]
MPI Rank 1: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 1: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *1] -> [64 x *1]
MPI Rank 1: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 1: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 1: Validating --> Keyword = SparseInputValue() :  -> [49292 x *1]
MPI Rank 1: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 1: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *1] -> [288 x *1]
MPI Rank 1: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 1: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *1] -> [64 x *1]
MPI Rank 1: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 1: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *1], [64 x *1], [1 x 1], [1 x 1] -> [51 x *1]
MPI Rank 1: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *1] -> [51 x 1 x *1]
MPI Rank 1: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *1], [51 x 1 x *1] -> [1]
MPI Rank 1: 
MPI Rank 1: Validating network. 11 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:05: Loaded model with 21 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:05: Training criterion node(s):
MPI Rank 1: 04/22/2016 01:02:05: 	CE = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 04/22/2016 01:02:05: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:08: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 04/22/2016 01:02:15:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.93745022; TotalTime = 6.8182s; SamplesPerSecond = 1501.9
MPI Rank 1: 04/22/2016 01:02:21:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.89571209; TotalTime = 6.6091s; SamplesPerSecond = 1549.4
MPI Rank 1: 04/22/2016 01:02:24: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8897429; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=16.7178
MPI Rank 1: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.820068    Perplexity = 6.1722783    
MPI Rank 1: 04/22/2016 01:02:27: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.820068
MPI Rank 1: 04/22/2016 01:02:30: CNTKCommandTrainEnd: train
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:30: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 04/22/2016 01:02:30: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: 04/22/2016 01:02:03: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank2
MPI Rank 2: 04/22/2016 01:02:03: -------------------------------------------------------------------
MPI Rank 2: 04/22/2016 01:02:03: Build info: 
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: 		Built time: Apr 21 2016 15:42:22
MPI Rank 2: 04/22/2016 01:02:03: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 2: 04/22/2016 01:02:03: 		Build type: Release
MPI Rank 2: 04/22/2016 01:02:03: 		Build target: GPU
MPI Rank 2: 04/22/2016 01:02:03: 		With 1bit-SGD: no
MPI Rank 2: 04/22/2016 01:02:03: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 2: 04/22/2016 01:02:03: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 2: 04/22/2016 01:02:03: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 04/22/2016 01:02:03: 		Build Branch: HEAD
MPI Rank 2: 04/22/2016 01:02:03: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 2: 04/22/2016 01:02:03: 		Built by svcphil on liana-08-w
MPI Rank 2: 04/22/2016 01:02:03: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 2: 04/22/2016 01:02:03: -------------------------------------------------------------------
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: Running on cntk-muc00 at 2016/04/22 01:02:03
MPI Rank 2: 04/22/2016 01:02:03: Command line: 
MPI Rank 2: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/22/2016 01:02:03: modelPath=$RunDir$/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=$DeviceId$
MPI Rank 2:     minibatchSize = $MBSize$
MPI Rank 2:     modelPath = $modelPath$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = $LRate$
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = $DataDir$/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=1
MPI Rank 2: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 04/22/2016 01:02:03: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2: MBSize=4096
MPI Rank 2: LRate=0.0001
MPI Rank 2: DeviceId=-1
MPI Rank 2: parallelTrain=true
MPI Rank 2: command = train
MPI Rank 2: precision = float
MPI Rank 2: traceGPUMemoryAllocations=0
MPI Rank 2: train = [
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: NDLNetworkBuilder = [
MPI Rank 2:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: reader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: cvReader = [
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: DeviceId=0
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=1
MPI Rank 2: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: dssm.cntk:command=train
MPI Rank 2: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 2: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:cvReader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 2: configparameters: dssm.cntk:DeviceId=0
MPI Rank 2: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 2: configparameters: dssm.cntk:MBSize=4096
MPI Rank 2: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 2:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 2: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 2: configparameters: dssm.cntk:precision=float
MPI Rank 2: configparameters: dssm.cntk:reader=[
MPI Rank 2:     readerType = LibSVMBinaryReader
MPI Rank 2:     miniBatchMode = Partial
MPI Rank 2:     randomize = 0
MPI Rank 2:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 2: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 2: configparameters: dssm.cntk:timestamping=true
MPI Rank 2: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 2: configparameters: dssm.cntk:train=[
MPI Rank 2:     action = train
MPI Rank 2:     numMBsToShowResult=10
MPI Rank 2:     deviceId=0
MPI Rank 2:     minibatchSize = 4096
MPI Rank 2:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize=102399
MPI Rank 2:         learningRatesPerSample = 0.0001
MPI Rank 2:         momentumPerMB = 0.9
MPI Rank 2:         maxEpochs=3
MPI Rank 2:         ParallelTrain=[
MPI Rank 2:             parallelizationStartEpoch=1
MPI Rank 2:             parallelizationMethod=ModelAveragingSGD
MPI Rank 2:             distributedMBReading=true
MPI Rank 2:             ModelAveragingSGD=[
MPI Rank 2:                 SyncFrequencyInFrames=1024
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2: 		gradUpdateType=none
MPI Rank 2: 		gradientClippingWithTruncation=true
MPI Rank 2: 		clippingThresholdPerSample=1#INF
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 04/22/2016 01:02:03: Commands: train
MPI Rank 2: 04/22/2016 01:02:03: Precision = "float"
MPI Rank 2: 04/22/2016 01:02:03: Using 1 CPU threads.
MPI Rank 2: 04/22/2016 01:02:03: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 2: 04/22/2016 01:02:03: CNTKCommandTrainInfo: train : 3
MPI Rank 2: 04/22/2016 01:02:03: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: ##############################################################################
MPI Rank 2: 04/22/2016 01:02:03: #                                                                            #
MPI Rank 2: 04/22/2016 01:02:03: # Action "train"                                                             #
MPI Rank 2: 04/22/2016 01:02:03: #                                                                            #
MPI Rank 2: 04/22/2016 01:02:03: ##############################################################################
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: CNTKCommandTrainBegin: train
MPI Rank 2: NDLBuilder Using GPU 0
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:03: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 2 roots:
MPI Rank 2: 	CE = CrossEntropyWithSoftmax()
MPI Rank 2: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 2: 
MPI Rank 2: Validating network. 21 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *1]
MPI Rank 2: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Query = SparseInputValue() :  -> [49292 x *1]
MPI Rank 2: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 2: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *1] -> [288 x *1]
MPI Rank 2: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 2: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *1] -> [64 x *1]
MPI Rank 2: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 2: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 2: Validating --> Keyword = SparseInputValue() :  -> [49292 x *1]
MPI Rank 2: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 2: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *1] -> [288 x *1]
MPI Rank 2: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 2: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *1] -> [64 x *1]
MPI Rank 2: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 2: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *1], [64 x *1], [1 x 1], [1 x 1] -> [51 x *1]
MPI Rank 2: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *1] -> [51 x 1 x *1]
MPI Rank 2: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *1], [51 x 1 x *1] -> [1]
MPI Rank 2: 
MPI Rank 2: Validating network. 11 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network, final pass.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:06: Loaded model with 21 nodes on GPU 0.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:06: Training criterion node(s):
MPI Rank 2: 04/22/2016 01:02:06: 	CE = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 04/22/2016 01:02:06: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:08: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 2: 04/22/2016 01:02:15:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.96188030; TotalTime = 6.8634s; SamplesPerSecond = 1492.0
MPI Rank 2: 04/22/2016 01:02:21:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.90950069; TotalTime = 6.6214s; SamplesPerSecond = 1546.5
MPI Rank 2: 04/22/2016 01:02:24: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8897429; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=16.7174
MPI Rank 2: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.820068    Perplexity = 6.1722783    
MPI Rank 2: 04/22/2016 01:02:27: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.820068
MPI Rank 2: 04/22/2016 01:02:30: CNTKCommandTrainEnd: train
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:30: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 04/22/2016 01:02:30: __COMPLETED__
MPI Rank 2: ~MPIWrapper
MPI Rank 3: 04/22/2016 01:02:04: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr_train.logrank3
MPI Rank 3: 04/22/2016 01:02:04: -------------------------------------------------------------------
MPI Rank 3: 04/22/2016 01:02:04: Build info: 
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: 		Built time: Apr 21 2016 15:42:22
MPI Rank 3: 04/22/2016 01:02:04: 		Last modified date: Sun Apr 17 20:45:43 2016
MPI Rank 3: 04/22/2016 01:02:04: 		Build type: Release
MPI Rank 3: 04/22/2016 01:02:04: 		Build target: GPU
MPI Rank 3: 04/22/2016 01:02:04: 		With 1bit-SGD: no
MPI Rank 3: 04/22/2016 01:02:04: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 3: 04/22/2016 01:02:04: 		CUB_PATH: C:\src\cub-1.4.1
MPI Rank 3: 04/22/2016 01:02:04: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 3: 04/22/2016 01:02:04: 		Build Branch: HEAD
MPI Rank 3: 04/22/2016 01:02:04: 		Build SHA1: 5016792195d54b61ee1ed837b2e99609567d083f
MPI Rank 3: 04/22/2016 01:02:04: 		Built by svcphil on liana-08-w
MPI Rank 3: 04/22/2016 01:02:04: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 3: 04/22/2016 01:02:04: -------------------------------------------------------------------
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: Running on cntk-muc00 at 2016/04/22 01:02:04
MPI Rank 3: 04/22/2016 01:02:04: Command line: 
MPI Rank 3: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.cntk  currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=1  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/22/2016 01:02:04: modelPath=$RunDir$/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=$DeviceId$
MPI Rank 3:     minibatchSize = $MBSize$
MPI Rank 3:     modelPath = $modelPath$
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = $LRate$
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:         keepCheckPointFiles = true
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = $ConfigDir$/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = $DataDir$/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=1
MPI Rank 3: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: 04/22/2016 01:02:04: modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3: MBSize=4096
MPI Rank 3: LRate=0.0001
MPI Rank 3: DeviceId=-1
MPI Rank 3: parallelTrain=true
MPI Rank 3: command = train
MPI Rank 3: precision = float
MPI Rank 3: traceGPUMemoryAllocations=0
MPI Rank 3: train = [
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:         keepCheckPointFiles = true
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: NDLNetworkBuilder = [
MPI Rank 3:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: reader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: cvReader = [
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: DeviceId=0
MPI Rank 3: timestamping=true
MPI Rank 3: numCPUThreads=1
MPI Rank 3: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 3: configparameters: dssm.cntk:command=train
MPI Rank 3: configparameters: dssm.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM
MPI Rank 3: configparameters: dssm.cntk:currentDirectory=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:cvReader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:DataDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData
MPI Rank 3: configparameters: dssm.cntk:DeviceId=0
MPI Rank 3: configparameters: dssm.cntk:LRate=0.0001
MPI Rank 3: configparameters: dssm.cntk:MBSize=4096
MPI Rank 3: configparameters: dssm.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3: configparameters: dssm.cntk:NDLNetworkBuilder=[
MPI Rank 3:     networkDescription = C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Text\SparseDSSM/dssm.ndl
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:numCPUThreads=1
MPI Rank 3: configparameters: dssm.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:parallelTrain=true
MPI Rank 3: configparameters: dssm.cntk:precision=float
MPI Rank 3: configparameters: dssm.cntk:reader=[
MPI Rank 3:     readerType = LibSVMBinaryReader
MPI Rank 3:     miniBatchMode = Partial
MPI Rank 3:     randomize = 0
MPI Rank 3:     file = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu\TestData/train.all.bin
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: configparameters: dssm.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu
MPI Rank 3: configparameters: dssm.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/stderr
MPI Rank 3: configparameters: dssm.cntk:timestamping=true
MPI Rank 3: configparameters: dssm.cntk:traceGPUMemoryAllocations=0
MPI Rank 3: configparameters: dssm.cntk:train=[
MPI Rank 3:     action = train
MPI Rank 3:     numMBsToShowResult=10
MPI Rank 3:     deviceId=0
MPI Rank 3:     minibatchSize = 4096
MPI Rank 3:     modelPath = C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3:     traceLevel = 1
MPI Rank 3:     SGD = [
MPI Rank 3:         epochSize=102399
MPI Rank 3:         learningRatesPerSample = 0.0001
MPI Rank 3:         momentumPerMB = 0.9
MPI Rank 3:         maxEpochs=3
MPI Rank 3:         ParallelTrain=[
MPI Rank 3:             parallelizationStartEpoch=1
MPI Rank 3:             parallelizationMethod=ModelAveragingSGD
MPI Rank 3:             distributedMBReading=true
MPI Rank 3:             ModelAveragingSGD=[
MPI Rank 3:                 SyncFrequencyInFrames=1024
MPI Rank 3:             ]
MPI Rank 3:         ]
MPI Rank 3: 		gradUpdateType=none
MPI Rank 3: 		gradientClippingWithTruncation=true
MPI Rank 3: 		clippingThresholdPerSample=1#INF
MPI Rank 3:         keepCheckPointFiles = true
MPI Rank 3:     ]
MPI Rank 3: ]
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 3: 04/22/2016 01:02:04: Commands: train
MPI Rank 3: 04/22/2016 01:02:04: Precision = "float"
MPI Rank 3: 04/22/2016 01:02:04: Using 1 CPU threads.
MPI Rank 3: 04/22/2016 01:02:04: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net
MPI Rank 3: 04/22/2016 01:02:04: CNTKCommandTrainInfo: train : 3
MPI Rank 3: 04/22/2016 01:02:04: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 3
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: ##############################################################################
MPI Rank 3: 04/22/2016 01:02:04: #                                                                            #
MPI Rank 3: 04/22/2016 01:02:04: # Action "train"                                                             #
MPI Rank 3: 04/22/2016 01:02:04: #                                                                            #
MPI Rank 3: 04/22/2016 01:02:04: ##############################################################################
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: CNTKCommandTrainBegin: train
MPI Rank 3: NDLBuilder Using GPU 0
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:04: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160422004638.754069\Text_SparseDSSM@release_gpu/Models/dssm.net.2'.
MPI Rank 3: 
MPI Rank 3: Post-processing network...
MPI Rank 3: 
MPI Rank 3: 2 roots:
MPI Rank 3: 	CE = CrossEntropyWithSoftmax()
MPI Rank 3: 	SIM = CosDistanceWithNegativeSamples()
MPI Rank 3: 
MPI Rank 3: Validating network. 21 nodes to process in pass 1.
MPI Rank 3: 
MPI Rank 3: Validating --> DSSMLabel = InputValue() :  -> [51 x 1 x *1]
MPI Rank 3: Validating --> G = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> WQ1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WQ0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Query = SparseInputValue() :  -> [49292 x *1]
MPI Rank 3: Validating --> WQ0_Q = Times (WQ0, Query) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 3: Validating --> WQ0_Q_Tanh = Tanh (WQ0_Q) : [288 x *1] -> [288 x *1]
MPI Rank 3: Validating --> WQ1_Q = Times (WQ1, WQ0_Q_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 3: Validating --> WQ1_Q_Tanh = Tanh (WQ1_Q) : [64 x *1] -> [64 x *1]
MPI Rank 3: Validating --> WD1 = LearnableParameter() :  -> [64 x 288]
MPI Rank 3: Validating --> WD0 = LearnableParameter() :  -> [288 x 49292]
MPI Rank 3: Validating --> Keyword = SparseInputValue() :  -> [49292 x *1]
MPI Rank 3: Validating --> WD0_D = Times (WD0, Keyword) : [288 x 49292], [49292 x *1] -> [288 x *1]
MPI Rank 3: Validating --> WD0_D_Tanh = Tanh (WD0_D) : [288 x *1] -> [288 x *1]
MPI Rank 3: Validating --> WD1_D = Times (WD1, WD0_D_Tanh) : [64 x 288], [288 x *1] -> [64 x *1]
MPI Rank 3: Validating --> WD1_D_Tanh = Tanh (WD1_D) : [64 x *1] -> [64 x *1]
MPI Rank 3: Validating --> S = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> N = LearnableParameter() :  -> [1 x 1]
MPI Rank 3: Validating --> SIM = CosDistanceWithNegativeSamples (WQ1_Q_Tanh, WD1_D_Tanh, S, N) : [64 x *1], [64 x *1], [1 x 1], [1 x 1] -> [51 x *1]
MPI Rank 3: Validating --> SIM_Scale = ElementTimes (G, SIM) : [1 x 1], [51 x *1] -> [51 x 1 x *1]
MPI Rank 3: Validating --> CE = CrossEntropyWithSoftmax (DSSMLabel, SIM_Scale) : [51 x 1 x *1], [51 x 1 x *1] -> [1]
MPI Rank 3: 
MPI Rank 3: Validating network. 11 nodes to process in pass 2.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Validating network, final pass.
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: 8 out of 21 nodes do not share the minibatch layout with the input data.
MPI Rank 3: 
MPI Rank 3: Post-processing network complete.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:06: Loaded model with 21 nodes on GPU 0.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:06: Training criterion node(s):
MPI Rank 3: 04/22/2016 01:02:06: 	CE = CrossEntropyWithSoftmax
MPI Rank 3: 
MPI Rank 3: 
MPI Rank 3: Allocating matrices for forward and/or backward propagation.
MPI Rank 3: 04/22/2016 01:02:06: No PreCompute nodes found, skipping PreCompute step.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:08: Starting Epoch 3: learning rate per sample = 0.000100  effective momentum = 0.900000  momentum as time constant = 38876.0 samples
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:08: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 3: 04/22/2016 01:02:15:  Epoch[ 3 of 3]-Minibatch[   1-  10, 40.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.91174297; TotalTime = 6.8926s; SamplesPerSecond = 1485.7
MPI Rank 3: 04/22/2016 01:02:21:  Epoch[ 3 of 3]-Minibatch[  11-  20, 80.00%]: SamplesSeen = 10240; TrainLossPerSample =  1.91370487; TotalTime = 6.6124s; SamplesPerSecond = 1548.6
MPI Rank 3: 04/22/2016 01:02:24: Finished Epoch[ 3 of 3]: [Training Set] TrainLossPerSample = 1.8897429; TotalSamplesSeen = 307197; AvgLearningRatePerSample = 9.9999997e-005; EpochTime=16.7182
MPI Rank 3: Final Results: Minibatch[1-25]: SamplesSeen = 409596    CE: CrossEntropyWithSoftmax/Sample = 1.820068    Perplexity = 6.1722783    
MPI Rank 3: 04/22/2016 01:02:27: Finished Epoch[ 3 of 3]: [Validation Set] TrainLossPerSample = 1.820068
MPI Rank 3: 04/22/2016 01:02:30: CNTKCommandTrainEnd: train
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:30: Action "train" complete.
MPI Rank 3: 
MPI Rank 3: 04/22/2016 01:02:30: __COMPLETED__
MPI Rank 3: ~MPIWrapper